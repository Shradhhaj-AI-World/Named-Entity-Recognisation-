{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Model without CRF\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "#from tflearn.data_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "data = pd.read_csv('NERData.csv', encoding='latin1', sep = ',')\n",
    "data = data.fillna(method=\"ffill\")\n",
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "n_words = len(words)\n",
    "tags = list(set(data[\"Tag\"].values))\n",
    "n_tags = len(tags)\n",
    "\n",
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "getter = SentenceGetter(data)\n",
    "sent = getter.get_next()\n",
    "sentences = getter.sentences\n",
    "max_len = 50\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=n_words - 1)\n",
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
    "#from keras.utils import to_categorical\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "input = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=n_words, output_dim=50, input_length=max_len)(input)\n",
    "model = Dropout(0.1)(model)\n",
    "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model)  # softmax output layer\n",
    "model = Model(input, out)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1711 samples, validate on 191 samples\n",
      "Epoch 1/100\n",
      "1711/1711 [==============================] - 34s 20ms/step - loss: 0.4440 - acc: 0.9317 - val_loss: 0.2498 - val_acc: 0.9479\n",
      "Epoch 2/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 0.2196 - acc: 0.9488 - val_loss: 0.2079 - val_acc: 0.9477\n",
      "Epoch 3/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 0.1582 - acc: 0.9560 - val_loss: 0.1404 - val_acc: 0.9604\n",
      "Epoch 4/100\n",
      "1711/1711 [==============================] - 22s 13ms/step - loss: 0.1135 - acc: 0.9670 - val_loss: 0.1132 - val_acc: 0.9666\n",
      "Epoch 5/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 0.0911 - acc: 0.9736 - val_loss: 0.0962 - val_acc: 0.9723\n",
      "Epoch 6/100\n",
      "1711/1711 [==============================] - 18s 11ms/step - loss: 0.0738 - acc: 0.9795 - val_loss: 0.0826 - val_acc: 0.9768\n",
      "Epoch 7/100\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 0.0583 - acc: 0.9842 - val_loss: 0.0707 - val_acc: 0.9842\n",
      "Epoch 8/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 0.0456 - acc: 0.9881 - val_loss: 0.0569 - val_acc: 0.9867\n",
      "Epoch 9/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 0.0353 - acc: 0.9910 - val_loss: 0.0526 - val_acc: 0.9868\n",
      "Epoch 10/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 0.0278 - acc: 0.9931 - val_loss: 0.0435 - val_acc: 0.9892\n",
      "Epoch 11/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 0.0223 - acc: 0.9948 - val_loss: 0.0418 - val_acc: 0.9902\n",
      "Epoch 12/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 0.0176 - acc: 0.9959 - val_loss: 0.0355 - val_acc: 0.9928\n",
      "Epoch 13/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 0.0144 - acc: 0.9967 - val_loss: 0.0359 - val_acc: 0.9921\n",
      "Epoch 14/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 0.0126 - acc: 0.9972 - val_loss: 0.0318 - val_acc: 0.9939\n",
      "Epoch 15/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 0.0104 - acc: 0.9976 - val_loss: 0.0300 - val_acc: 0.9941\n",
      "Epoch 16/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 0.0088 - acc: 0.9980 - val_loss: 0.0308 - val_acc: 0.9939\n",
      "Epoch 17/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 0.0073 - acc: 0.9983 - val_loss: 0.0288 - val_acc: 0.9948\n",
      "Epoch 18/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 0.0065 - acc: 0.9985 - val_loss: 0.0260 - val_acc: 0.9955\n",
      "Epoch 19/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 0.0056 - acc: 0.9986 - val_loss: 0.0259 - val_acc: 0.9950\n",
      "Epoch 20/100\n",
      "1711/1711 [==============================] - 20s 11ms/step - loss: 0.0046 - acc: 0.9990 - val_loss: 0.0284 - val_acc: 0.9940\n",
      "Epoch 21/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 0.0040 - acc: 0.9991 - val_loss: 0.0255 - val_acc: 0.9958\n",
      "Epoch 22/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 0.0032 - acc: 0.9992 - val_loss: 0.0275 - val_acc: 0.9947\n",
      "Epoch 23/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 0.0030 - acc: 0.9993 - val_loss: 0.0264 - val_acc: 0.9954\n",
      "Epoch 24/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0254 - val_acc: 0.9959\n",
      "Epoch 25/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0271 - val_acc: 0.9951\n",
      "Epoch 26/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0254 - val_acc: 0.9961\n",
      "Epoch 27/100\n",
      "1711/1711 [==============================] - 20s 11ms/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0274 - val_acc: 0.9957\n",
      "Epoch 28/100\n",
      "1711/1711 [==============================] - 20s 11ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0264 - val_acc: 0.9962\n",
      "Epoch 29/100\n",
      "1711/1711 [==============================] - 20s 11ms/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0274 - val_acc: 0.9958\n",
      "Epoch 30/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0254 - val_acc: 0.9961\n",
      "Epoch 31/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 9.6791e-04 - acc: 0.9998 - val_loss: 0.0256 - val_acc: 0.9962\n",
      "Epoch 32/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 8.0078e-04 - acc: 0.9998 - val_loss: 0.0277 - val_acc: 0.9959\n",
      "Epoch 33/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 9.8548e-04 - acc: 0.9998 - val_loss: 0.0287 - val_acc: 0.9956\n",
      "Epoch 34/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 8.0278e-04 - acc: 0.9998 - val_loss: 0.0277 - val_acc: 0.9960\n",
      "Epoch 35/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 6.9395e-04 - acc: 0.9998 - val_loss: 0.0279 - val_acc: 0.9961\n",
      "Epoch 36/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 6.7200e-04 - acc: 0.9998 - val_loss: 0.0288 - val_acc: 0.9960\n",
      "Epoch 37/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 6.8314e-04 - acc: 0.9998 - val_loss: 0.0330 - val_acc: 0.9948\n",
      "Epoch 38/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 6.1921e-04 - acc: 0.9998 - val_loss: 0.0283 - val_acc: 0.9966\n",
      "Epoch 39/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 5.1585e-04 - acc: 0.9999 - val_loss: 0.0284 - val_acc: 0.9962\n",
      "Epoch 40/100\n",
      "1711/1711 [==============================] - 22s 13ms/step - loss: 4.6623e-04 - acc: 0.9998 - val_loss: 0.0300 - val_acc: 0.9957\n",
      "Epoch 41/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 5.6380e-04 - acc: 0.9999 - val_loss: 0.0281 - val_acc: 0.9960\n",
      "Epoch 42/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 5.0694e-04 - acc: 0.9999 - val_loss: 0.0281 - val_acc: 0.9960\n",
      "Epoch 43/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 4.1889e-04 - acc: 0.9999 - val_loss: 0.0315 - val_acc: 0.9947\n",
      "Epoch 44/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 4.9079e-04 - acc: 0.9998 - val_loss: 0.0282 - val_acc: 0.9958\n",
      "Epoch 45/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 4.8427e-04 - acc: 0.9998 - val_loss: 0.0275 - val_acc: 0.9961\n",
      "Epoch 46/100\n",
      "1711/1711 [==============================] - 23s 14ms/step - loss: 4.2875e-04 - acc: 0.9999 - val_loss: 0.0273 - val_acc: 0.9965\n",
      "Epoch 47/100\n",
      "1711/1711 [==============================] - 22s 13ms/step - loss: 3.7704e-04 - acc: 0.9999 - val_loss: 0.0284 - val_acc: 0.9961\n",
      "Epoch 48/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 4.0672e-04 - acc: 0.9999 - val_loss: 0.0274 - val_acc: 0.9961\n",
      "Epoch 49/100\n",
      "1711/1711 [==============================] - 21s 13ms/step - loss: 3.7984e-04 - acc: 0.9999 - val_loss: 0.0310 - val_acc: 0.9956\n",
      "Epoch 50/100\n",
      "1711/1711 [==============================] - 22s 13ms/step - loss: 3.6141e-04 - acc: 0.9999 - val_loss: 0.0297 - val_acc: 0.9955\n",
      "Epoch 51/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 2.6752e-04 - acc: 0.9999 - val_loss: 0.0312 - val_acc: 0.9956\n",
      "Epoch 52/100\n",
      "1711/1711 [==============================] - 21s 13ms/step - loss: 3.2196e-04 - acc: 0.9999 - val_loss: 0.0342 - val_acc: 0.9949\n",
      "Epoch 53/100\n",
      "1711/1711 [==============================] - 21s 13ms/step - loss: 4.3199e-04 - acc: 0.9998 - val_loss: 0.0329 - val_acc: 0.9955\n",
      "Epoch 54/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 3.3869e-04 - acc: 0.9999 - val_loss: 0.0307 - val_acc: 0.9955\n",
      "Epoch 55/100\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 2.3887e-04 - acc: 1.0000 - val_loss: 0.0303 - val_acc: 0.9957\n",
      "Epoch 56/100\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 3.1961e-04 - acc: 0.9999 - val_loss: 0.0279 - val_acc: 0.9960\n",
      "Epoch 57/100\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 2.7795e-04 - acc: 0.9999 - val_loss: 0.0292 - val_acc: 0.9959\n",
      "Epoch 58/100\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 3.0097e-04 - acc: 0.9999 - val_loss: 0.0310 - val_acc: 0.9959\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1711/1711 [==============================] - 19s 11ms/step - loss: 2.7021e-04 - acc: 0.9999 - val_loss: 0.0306 - val_acc: 0.9958\n",
      "Epoch 60/100\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 3.0065e-04 - acc: 0.9999 - val_loss: 0.0303 - val_acc: 0.9955\n",
      "Epoch 61/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 2.1483e-04 - acc: 0.9999 - val_loss: 0.0294 - val_acc: 0.9961\n",
      "Epoch 62/100\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 4.0190e-04 - acc: 0.9999 - val_loss: 0.0329 - val_acc: 0.9953\n",
      "Epoch 63/100\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 3.5149e-04 - acc: 0.9999 - val_loss: 0.0315 - val_acc: 0.9956\n",
      "Epoch 64/100\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 2.8292e-04 - acc: 0.9999 - val_loss: 0.0301 - val_acc: 0.9957\n",
      "Epoch 65/100\n",
      "1711/1711 [==============================] - 18s 11ms/step - loss: 3.3766e-04 - acc: 0.9999 - val_loss: 0.0312 - val_acc: 0.9957\n",
      "Epoch 66/100\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 2.3301e-04 - acc: 0.9999 - val_loss: 0.0348 - val_acc: 0.9951\n",
      "Epoch 67/100\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 2.7862e-04 - acc: 0.9999 - val_loss: 0.0293 - val_acc: 0.9958\n",
      "Epoch 68/100\n",
      "1711/1711 [==============================] - 18s 11ms/step - loss: 2.9627e-04 - acc: 0.9999 - val_loss: 0.0306 - val_acc: 0.9960\n",
      "Epoch 69/100\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 2.8809e-04 - acc: 0.9999 - val_loss: 0.0279 - val_acc: 0.9958\n",
      "Epoch 70/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 2.5824e-04 - acc: 0.9999 - val_loss: 0.0324 - val_acc: 0.9957\n",
      "Epoch 71/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 2.4147e-04 - acc: 0.9999 - val_loss: 0.0343 - val_acc: 0.9953\n",
      "Epoch 72/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 2.9858e-04 - acc: 0.9999 - val_loss: 0.0328 - val_acc: 0.9954\n",
      "Epoch 73/100\n",
      "1711/1711 [==============================] - 22s 13ms/step - loss: 2.3694e-04 - acc: 0.9999 - val_loss: 0.0322 - val_acc: 0.9959\n",
      "Epoch 74/100\n",
      "1711/1711 [==============================] - 22s 13ms/step - loss: 2.5967e-04 - acc: 0.9999 - val_loss: 0.0350 - val_acc: 0.9951\n",
      "Epoch 75/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 1.9202e-04 - acc: 0.9999 - val_loss: 0.0337 - val_acc: 0.9955\n",
      "Epoch 76/100\n",
      "1711/1711 [==============================] - 22s 13ms/step - loss: 2.3709e-04 - acc: 0.9999 - val_loss: 0.0331 - val_acc: 0.9958\n",
      "Epoch 77/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 2.5116e-04 - acc: 0.9999 - val_loss: 0.0325 - val_acc: 0.9960\n",
      "Epoch 78/100\n",
      "1711/1711 [==============================] - 21s 13ms/step - loss: 2.9285e-04 - acc: 0.9999 - val_loss: 0.0380 - val_acc: 0.9945\n",
      "Epoch 79/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 2.2151e-04 - acc: 0.9999 - val_loss: 0.0320 - val_acc: 0.9956\n",
      "Epoch 80/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 1.7579e-04 - acc: 1.0000 - val_loss: 0.0375 - val_acc: 0.9952\n",
      "Epoch 81/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 3.0202e-04 - acc: 0.9999 - val_loss: 0.0335 - val_acc: 0.9954\n",
      "Epoch 82/100\n",
      "1711/1711 [==============================] - 21s 13ms/step - loss: 2.8325e-04 - acc: 0.9999 - val_loss: 0.0331 - val_acc: 0.9958\n",
      "Epoch 83/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 1.9231e-04 - acc: 0.9999 - val_loss: 0.0331 - val_acc: 0.9953\n",
      "Epoch 84/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 1.9172e-04 - acc: 0.9999 - val_loss: 0.0366 - val_acc: 0.9952\n",
      "Epoch 85/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 2.0376e-04 - acc: 0.9999 - val_loss: 0.0334 - val_acc: 0.9956\n",
      "Epoch 86/100\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 2.1709e-04 - acc: 0.9999 - val_loss: 0.0399 - val_acc: 0.9943\n",
      "Epoch 87/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 1.9974e-04 - acc: 0.9999 - val_loss: 0.0336 - val_acc: 0.9955\n",
      "Epoch 88/100\n",
      "1711/1711 [==============================] - 20s 11ms/step - loss: 2.4562e-04 - acc: 0.9999 - val_loss: 0.0345 - val_acc: 0.9952\n",
      "Epoch 89/100\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 1.8508e-04 - acc: 0.9999 - val_loss: 0.0351 - val_acc: 0.9951\n",
      "Epoch 90/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 2.1958e-04 - acc: 0.9999 - val_loss: 0.0335 - val_acc: 0.9958\n",
      "Epoch 91/100\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 2.1934e-04 - acc: 0.9999 - val_loss: 0.0323 - val_acc: 0.9955\n",
      "Epoch 92/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 2.1003e-04 - acc: 0.9999 - val_loss: 0.0338 - val_acc: 0.9953\n",
      "Epoch 93/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 2.3744e-04 - acc: 0.9999 - val_loss: 0.0393 - val_acc: 0.9946\n",
      "Epoch 94/100\n",
      "1711/1711 [==============================] - 19s 11ms/step - loss: 2.0689e-04 - acc: 0.9999 - val_loss: 0.0350 - val_acc: 0.9952\n",
      "Epoch 95/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 2.0918e-04 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 0.9957\n",
      "Epoch 96/100\n",
      "1711/1711 [==============================] - 21s 12ms/step - loss: 2.2121e-04 - acc: 0.9999 - val_loss: 0.0351 - val_acc: 0.9954\n",
      "Epoch 97/100\n",
      "1711/1711 [==============================] - 20s 12ms/step - loss: 2.1602e-04 - acc: 0.9999 - val_loss: 0.0362 - val_acc: 0.9952\n",
      "Epoch 98/100\n",
      "1711/1711 [==============================] - 22s 13ms/step - loss: 2.0299e-04 - acc: 0.9999 - val_loss: 0.0370 - val_acc: 0.9952\n",
      "Epoch 99/100\n",
      "1711/1711 [==============================] - 16s 10ms/step - loss: 2.0614e-04 - acc: 0.9999 - val_loss: 0.0355 - val_acc: 0.9953\n",
      "Epoch 100/100\n",
      "1711/1711 [==============================] - 20s 11ms/step - loss: 2.1004e-04 - acc: 0.9999 - val_loss: 0.0348 - val_acc: 0.9953\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_tr, np.array(y_tr), batch_size=32, epochs=100, validation_split=0.1, verbose=1)\n",
    "\n",
    "#model.save('mmmodel.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "#del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "#modelkk = load_model('mmmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"An individual wiping command should be implemented by setting the level of WW and INT-line from HIGH to LOW for the parameterized time p_t_einzelwischhub body control module\".split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_sent = pad_sequences(sequences=[[word2idx.get(w, 0) for w in test_sentence]],\n",
    "                            padding=\"post\", value=0, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newpredict(tt):\n",
    "    result = []\n",
    "    x_test_sent = pad_sequences(sequences=[[word2idx.get(w, 0) for w in tt]],\n",
    "                            padding=\"post\", value=0, maxlen=max_len)\n",
    "    p = model.predict(np.array([x_test_sent[0]]))\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    for w, pred in zip(tt, p[0]):\n",
    "        result.append((w, tags[pred]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('An', 'O'),\n",
       " ('individual', 'O'),\n",
       " ('wiping', 'O'),\n",
       " ('command', 'O'),\n",
       " ('should', 'O'),\n",
       " ('be', 'O'),\n",
       " ('implemented', 'O'),\n",
       " ('by', 'O'),\n",
       " ('setting', 'O'),\n",
       " ('the', 'O'),\n",
       " ('level', 'O'),\n",
       " ('of', 'O'),\n",
       " ('WW', 'O'),\n",
       " ('and', 'O'),\n",
       " ('INT-line', 'O'),\n",
       " ('from', 'O'),\n",
       " ('HIGH', 'O'),\n",
       " ('to', 'O'),\n",
       " ('LOW', 'O'),\n",
       " ('for', 'O'),\n",
       " ('the', 'O'),\n",
       " ('parameterized', 'O'),\n",
       " ('time', 'O'),\n",
       " ('p_t_einzelwischhub', 'O'),\n",
       " ('body', 'O'),\n",
       " ('control', 'O'),\n",
       " ('module', 'O')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newpredict(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'O'),\n",
       " ('system', 'Network_Component'),\n",
       " ('should', 'O'),\n",
       " ('do', 'O'),\n",
       " ('the', 'O'),\n",
       " ('validation', 'Action'),\n",
       " ('for', 'O'),\n",
       " ('confirm', 'Action'),\n",
       " ('password', 'Attribute'),\n",
       " ('text', 'O'),\n",
       " ('on', 'O'),\n",
       " ('submit', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('form', 'O')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[('The', 'O'),\n",
    " ('system', 'Network_Component'),\n",
    " ('should', 'O'),\n",
    " ('do', 'O'),\n",
    " ('the', 'O'),\n",
    " ('validation', 'Action'),\n",
    " ('for', 'O'),\n",
    " ('confirm', 'Action'),\n",
    " ('password', 'Attribute'),\n",
    " ('text', 'O'),\n",
    " ('on', 'O'),\n",
    " ('submit', 'O'),\n",
    " ('of', 'O'),\n",
    " ('the', 'O'),\n",
    " ('form', 'O')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1902/1902 [==============================] - 5s 2ms/step\n",
      "acc: 99.95%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_tr, np.array(y_tr), verbose=1)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('model2.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model1.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hp\\\\python programs in anaconda class notes\\\\FOr ESDS Github\\\\NER-Named-Entity-Recognition-master'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1902/1902 [==============================] - 8s 4ms/step\n",
      "acc: 99.95%\n"
     ]
    }
   ],
   "source": [
    "score = loaded_model.evaluate(X_tr, np.array(y_tr), verbose=1)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Save\n",
    "np.save('W2i.npy', word2idx) \n",
    "\n",
    "# Load\n",
    "#word2idx = np.load('C:\\\\Users\\\\sharath\\\\Desktop\\\\exp\\\\W2i.npy').item()\n",
    "\n",
    "\n",
    "# Save\n",
    "np.save('T2i.npy', tag2idx) \n",
    "\n",
    "# Load\n",
    "#tag2idx = np.load('C:\\\\Users\\\\sharath\\\\Desktop\\\\exp\\\\T2i.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilstmfinal(test_sentence):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from keras.models import model_from_json\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "    from keras.models import Model, Input\n",
    "    from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from keras.utils import to_categorical\n",
    "    import numpy\n",
    "    numpy.random.seed(7)\n",
    "    word2idx = np.load('W2i.npy').item()\n",
    "    tag2idx = np.load('T2i.npy').item()\n",
    "    # load json and create model\n",
    "    json_file = open('model2.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"model1.h5\")\n",
    "    loaded_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    test_sentence = test_sentence.split(\" \")\n",
    "    x_test_sent = pad_sequences(sequences=[[word2idx.get(w, 0) for w in test_sentence]],\n",
    "                            padding=\"post\", value=0, maxlen=50)\n",
    "    p = loaded_model.predict(np.array([x_test_sent[0]]))\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    pls = []\n",
    "    p = loaded_model.predict(np.array([x_test_sent[0]]))\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    for w, pred in zip(test_sentence, p[0]):\n",
    "        pls.append(pred)\n",
    "    revsubs = { v:k for k,v in tag2idx.items()}\n",
    "    entit = [revsubs.get(item,item) for item in pls]\n",
    "    final = list(zip(test_sentence,entit))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"The system shall allow a registered visitor to load a custom filter.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'O'),\n",
       " ('system', 'O'),\n",
       " ('shall', 'O'),\n",
       " ('allow', 'O'),\n",
       " ('a', 'O'),\n",
       " ('registered', 'actor'),\n",
       " ('visitor', 'actor'),\n",
       " ('to', 'O'),\n",
       " ('load', 'action'),\n",
       " ('a', 'O'),\n",
       " ('custom', 'attribute'),\n",
       " ('filter.', 'attribute')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilstmfinal(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
